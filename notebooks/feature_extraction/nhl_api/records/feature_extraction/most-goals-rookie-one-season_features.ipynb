{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# NHL Draft dataset\n# Feature extraction\n# Records: \n## Most Goals by a Rookie in a Single Season\nThis notebook presents feature extraction from NHL Records data obtained from NHL Records API Records endpoint.\n### Data collection summary\nDataset generated from a JSON received from the NHL Records API, contains response to the request for all draft records.\n\nFor details, see notebook `notebooks/feature_extraction/nhl_api.ipynb`."
    },
    {
      "cell_type": "markdown",
      "source": "## Preparations\n### Import dependencies",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": "import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom time import time\nimport sys\nimport os",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "data": {
            "text/plain": "[\u0027.git\u0027,\n \u0027.gitattributes\u0027,\n \u0027.gitignore\u0027,\n \u0027.idea\u0027,\n \u0027data\u0027,\n \u0027design\u0027,\n \u0027main.py\u0027,\n \u0027models\u0027,\n \u0027notebooks\u0027,\n \u0027README.md\u0027,\n \u0027requirements.txt\u0027,\n \u0027src\u0027]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 2
        }
      ],
      "source": "os.chdir(\u0027Documents/repos/nhl_draft/\u0027)\nsys.path.append(\u0027src\u0027)\nos.listdir()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Load data",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "----- NHL Records\n--- Most Goals, Rookie, Season dataset\n\n----- DataFrame with NHL Draft Data loaded\nin 0.07 seconds\nwith 3,377 rows\nand 35 columns\n-- Column names:\n Index([\u0027activePlayer\u0027, \u0027assists\u0027, \u0027assistsPerGpMin20\u0027, \u0027firstGoals\u0027,\n       \u0027firstName\u0027, \u0027fiveGoalGames\u0027, \u0027fourGoalGames\u0027, \u0027gameWinningGoals\u0027,\n       \u0027gamesInSchedule\u0027, \u0027gamesPlayed\u0027, \u0027goals\u0027, \u0027goalsPerGpMin20\u0027,\n       \u0027goalsPerGpMin50\u0027, \u0027id\u0027, \u0027lastName\u0027, \u0027overtimeAssists\u0027, \u0027overtimeGoals\u0027,\n       \u0027overtimePoints\u0027, \u0027penalties\u0027, \u0027penaltyMinutes\u0027, \u0027playerId\u0027, \u0027points\u0027,\n       \u0027pointsPerGpMin50\u0027, \u0027positionCode\u0027, \u0027powerPlayGoals\u0027, \u0027rookieFlag\u0027,\n       \u0027seasonId\u0027, \u0027sevenGoalGames\u0027, \u0027shorthandedGoals\u0027, \u0027shots\u0027,\n       \u0027sixGoalGames\u0027, \u0027teamAbbrevs\u0027, \u0027teamNames\u0027, \u0027threeGoalGames\u0027,\n       \u0027threeOrMoreGoalGames\u0027],\n      dtype\u003d\u0027object\u0027)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "rec_name \u003d \u0027most-goals-rookie-one-season\u0027\nrec_file \u003d \u0027data/nhl_api/records/records_main.csv\u0027\ndf_rec \u003d pd.read_csv(rec_file)\nmask \u003d df_rec[\u0027descriptionKey\u0027] \u003d\u003d rec_name\nname \u003d df_rec.loc[mask, \u0027description\u0027].values[0]\nprint(\"----- NHL Records\\n---\", name, \u0027dataset\\n\u0027)\n\nfile \u003d \u0027data/nhl_api/records/\u0027 + \\\n       rec_name + \u0027.csv\u0027\nt \u003d time()\ndf \u003d pd.read_csv(file)\nelapsed \u003d time() - t\nprint(\"----- DataFrame with NHL Draft Data loaded\"\n      \"\\nin {0:.2f} seconds\".format(elapsed) + \n      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n      .format(df.shape[0], df.shape[1]) + \n      \"\\n-- Column names:\\n\", df.columns)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Rescaling variables\nFrom [machinelearningmastery.com](https://machinelearningmastery.com/normalize-standardize-time-series-data-python/), [wikipedia](https://en.wikipedia.org/wiki/Feature_scaling), and a [lecture by Andrew Ng](http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course\u003dMachineLearning\u0026video\u003d03.1-LinearRegressionII-FeatureScaling\u0026speed\u003d100/) on Feature Scaling:\n\nSome machine learning algorithms will achieve better performance if data has a consistent scale or distribution. Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization.\n\nFor example, the majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n\nAnother reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it. In stochastic gradient descent, feature scaling can sometimes improve the convergence speed of the algorithm. In support vector machines, it can reduce the time to find support vectors. Note that feature scaling changes the SVM result.\n\nTwo techniques that can be used to consistently rescale data are :\n### Normalization \n* Also known as feature scaling or unity-based normalization\n* Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n* Normalization can be useful, and even required in some machine learning algorithms when data has input values with differing scales.\n* It may be required for algorithms, like k-Nearest neighbors, which uses distance calculations and Linear Regression and Artificial Neural Networks that weight input values.\n* Normalization requires the knowledge or accurate estimation of the minimum and maximum observable values (can be estimated from the available data).\n* If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting.\n* If the data presents a time series that is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use.\n* Types of normalization:\n    * Rescaling (min-max normalization)  \n$ \\large{ X\u0027 \u003d \\frac{ X - X_{min} } { X_{max} - X_{min} } } $\n    * Rescaling between an arbitrary set of values  \n$ \\large{ X\u0027 \u003d a + \\frac{ (X - X_{min})(b - a) } { X_{max} - X_{min} } } $\n    * Mean normalization  \n$ \\large{ X\u0027 \u003d \\frac{ X - \\mu_X } { X_{max} - X_{min} } } $\n\nVariables can be normalized using the `scikit-learn` object `MinMaxScaler`.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Normalizing features\n [\u0027assists\u0027, \u0027firstGoals\u0027, \u0027gameWinningGoals\u0027, \u0027gamesPlayed\u0027, \u0027goals\u0027, \u0027overtimeGoals\u0027, \u0027overtimePoints\u0027, \u0027penalties\u0027, \u0027points\u0027, \u0027powerPlayGoals\u0027, \u0027shots\u0027]\n\nFeature: assists\nMin: 0.000000, Max: 70.000000\n\nFeature: firstGoals\nMin: 0.000000, Max: 14.000000\n\nFeature: gameWinningGoals\nMin: 0.000000, Max: 9.000000\n\nFeature: gamesPlayed\nMin: 1.000000, Max: 84.000000\n\nFeature: goals\nMin: 3.000000, Max: 76.000000\n\nFeature: overtimeGoals\nMin: 0.000000, Max: 4.000000\n\nFeature: overtimePoints\nMin: 0.000000, Max: 6.000000\n\nFeature: penalties\nMin: 0.000000, Max: 103.000000\n\nFeature: points\nMin: 3.000000, Max: 132.000000\n\nFeature: powerPlayGoals\nMin: 0.000000, Max: 31.000000\n\nFeature: shots\nMin: 3.000000, Max: 425.000000\nAll columns normalized!\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# list of columns to normalize\ncols \u003d [\u0027assists\u0027, \u0027firstGoals\u0027, \u0027gameWinningGoals\u0027,\n        \u0027gamesPlayed\u0027, \u0027goals\u0027, \u0027overtimeGoals\u0027,\n        \u0027overtimePoints\u0027, \u0027penalties\u0027, \u0027points\u0027,\n        \u0027powerPlayGoals\u0027, \u0027shots\u0027]\n\nprint(\"Normalizing features\\n\", cols)\nfor col in cols:\n    # prepare data for normalization\n    values \u003d df[col].values\n    values \u003d values.reshape((len(values), 1))\n    # train the normalization\n    scaler \u003d MinMaxScaler(feature_range\u003d(0, 1))\n    scaler \u003d scaler.fit(values)\n    print(\"\\nFeature:\", col)\n    print(\u0027Min: %f, Max: %f\u0027 % (scaler.data_min_, scaler.data_max_))\n    # normalize feature and save as a new column\n    normalized \u003d scaler.transform(values)\n    df[col + \u0027_norm\u0027] \u003d normalized\nprint(\"All columns normalized!\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "\u003cclass \u0027pandas.core.frame.DataFrame\u0027\u003e\nRangeIndex: 3377 entries, 0 to 3376\nData columns (total 46 columns):\nactivePlayer             3377 non-null bool\nassists                  3377 non-null int64\nassistsPerGpMin20        731 non-null float64\nfirstGoals               3377 non-null int64\nfirstName                3377 non-null object\nfiveGoalGames            308 non-null float64\nfourGoalGames            308 non-null float64\ngameWinningGoals         3377 non-null int64\ngamesInSchedule          3377 non-null int64\ngamesPlayed              3377 non-null int64\ngoals                    3377 non-null int64\ngoalsPerGpMin20          340 non-null float64\ngoalsPerGpMin50          4 non-null float64\nid                       3377 non-null int64\nlastName                 3377 non-null object\novertimeAssists          3377 non-null int64\novertimeGoals            3377 non-null int64\novertimePoints           3377 non-null int64\npenalties                3377 non-null int64\npenaltyMinutes           3377 non-null int64\nplayerId                 3377 non-null int64\npoints                   3377 non-null int64\npointsPerGpMin50         235 non-null float64\npositionCode             3377 non-null object\npowerPlayGoals           3191 non-null float64\nrookieFlag               3377 non-null bool\nseasonId                 3377 non-null int64\nsevenGoalGames           308 non-null float64\nshorthandedGoals         3191 non-null float64\nshots                    2885 non-null float64\nsixGoalGames             308 non-null float64\nteamAbbrevs              3377 non-null object\nteamNames                3377 non-null object\nthreeGoalGames           308 non-null float64\nthreeOrMoreGoalGames     308 non-null float64\nassists_norm             3377 non-null float64\nfirstGoals_norm          3377 non-null float64\ngameWinningGoals_norm    3377 non-null float64\ngamesPlayed_norm         3377 non-null float64\ngoals_norm               3377 non-null float64\novertimeGoals_norm       3377 non-null float64\novertimePoints_norm      3377 non-null float64\npenalties_norm           3377 non-null float64\npoints_norm              3377 non-null float64\npowerPlayGoals_norm      3191 non-null float64\nshots_norm               2885 non-null float64\ndtypes: bool(2), float64(24), int64(15), object(5)\nmemory usage: 1.1+ MB\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "df.info()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Standardization\n* Standardization is another type of rescaling that is more robust to new values being outside the range of expected values than normalization. \n* Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. \n    * This can be thought of as subtracting the mean value, or centering the data, and scaling by standard deviation.\n* Like normalization, standardization can be useful, and even required in some machine learning algorithms when your time series data has input values with differing scales.\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}